<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="keywords" content="diffusion, uqdm, progressive, coding, paper, project, citation, justus, will">


  <title> UQDM </title>

  <link rel="icon" type="image/svg" href="images/favicon.svg?">
  <link rel=”mask-icon” href="images/favicon.svg?" color=”#ff3500">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link href="css/bulma.min.css" rel="stylesheet">
  <link href="css/bulma-carousel.min.css" rel="stylesheet">
  <link href="css/bulma-slider.min.css" rel="stylesheet">
  <link href="css/fontawesome.all.min.css" rel="stylesheet">
  <link href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" rel="stylesheet">
  <link href="css/index.css" rel="stylesheet">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="js/fontawesome.all.min.js"></script>
  <script src="js/bulma-carousel.min.js"></script>
  <script src="js/bulma-slider.min.js"></script>
  <script src="js/index.js"></script>
</head>

<body>
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Progressive Compression with Universally Quantized Diffusion Models</h1>
          <!-- Paper authors -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://yiboyang.com/about/" target="_blank">Yibo Yang</a>*,</span>
              <span class="author-block">
                <a href="https://www.justuswill.com" target="_blank">Justus Will</a>*,</span>
                <span class="author-block">
                  <a href="https://www.stephanmandt.com" target="_blank">Stephan Mandt</a>
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">University of California, Irvine<br>Oral at ICLR '25</span>
            <span class="eql-cntrb"><small><br><sup>*</sup>Equal Contribution</small></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">

              <!-- Arxiv PDF link -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2412.10935v1" target="_blank"
                class="external-link button is-normal is-dark">
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                <span>Paper</span>
                </a>
              </span>

              <!-- GitHub link -->
              <span class="link-block">
                <a href="https://github.com/mandt-lab/uqdm" target="_blank"
                class="external-link button is-normal is-dark">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
                </a>
              </span>

              <!-- ArXiv abstract Link -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2412.10935v1" target="_blank"
                class="external-link button is-normal is-dark">
                <span class="icon">
                  <i class="ai ai-arxiv"></i>
                </span>
                <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser image -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="images/high_samples_grid_full.png" style="height: auto; width: auto;" alt="Sample reconstructions"/>
      <h2 class="subtitle has-text-centered">
        Example reconstructions from several traditional and neural codecs, chosen at roughly
        similar bitrates. At high bitrates, our UQDM method preserves details (e.g. shape and color pattern
        of the spider, or sharpness of the calligraphy) better than other neural codecs. Note that among the
        methods considered here, only ours and CTC (<a href="https://arxiv.org/abs/2303.05715" target="_blank">Jeon et al., 2023</a>) implement progressive coding.
      </h2>
    </div>
  </div>
</section>

<!-- TLDR -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">TLDR</h2>
        <div class="content has-text-justified">
          <p>
            Our new form of diffusion model, UQDM, enables practical
            <strong>progressive compression</strong> with an unconditional diffusion model -
            avoiding the computational intractability of Gaussian channel simulation by using universal quantization.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Full Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Diffusion probabilistic models have achieved mainstream success in many generative modeling tasks, from image generation to solving inverse problems. A
            distinct feature of these models is that they correspond to deep hierarchical latent
            variable models optimizing a variational evidence lower bound (ELBO) on the
            data likelihood. Drawing on a basic connection between likelihood modeling and
            compression, we explore the potential of diffusion models for progressive coding,
            resulting in a sequence of bits that can be incrementally transmitted and decoded
            with progressively improving reconstruction quality. Unlike prior work based on
            Gaussian diffusion or conditional diffusion models, we propose a new form of
            diffusion model with uniform noise in the forward process, whose negative ELBO
            corresponds to the end-to-end compression cost using universal quantization. We
            obtain promising first results on image compression, achieving competitive rate-distortion-realism results on a wide range of bit-rates with a single model, bringing
            neural codecs a step closer to practical deployment.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Methodology -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="column has-text-centered">
      <h2 class="title is-3">Methodology</h2>
      <div class="content has-text-justified">
        <p>
          A progressive compression algorithm allows for lossy reconstructions with improving quality as more bits are sent, up till a lossless reconstruction. This results
          in variable-rate compression with a single bitstream, and is highly desirable in practical applications. We follow the same conceptual framework as in
          (<a href="https://arxiv.org/abs/2006.11239" target="_blank">Ho et al., 2020</a>; <a href="https://arxiv.org/abs/2206.08889" target="_blank">Theis et al., 2022</a>). Crucially, however, we avoid Gaussian channel simulation and bits-back coding, by instead using universal quantization as follows:
        </p>
      </div>
        <img src="images/algorithm.png" style="height: auto; width: auto;" alt="algorithm pseudocode"/>
        <img src="images/sketch.png" style="height: auto; width: auto;" alt="algorithm sketch"/>
      </div>
      <div class="content has-text-justified">
        <p>
          To facilitate this, our diffusion model replaces the Gaussian conditional distributions with uniform distributions,
          allowing for end-to-end training where our NELBO training objective naturally corresponds to the lossless
          coding cost of our progressive codec. For more details and results, see our paper.
        </p>
    </div>
  </div>
</section>


<!-- BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <pre><code>
      @article{yang2025universal,
        title={Progressive Compression with Universally Quantized Diffusion Models},
        author={Yibo Yang and Justus Will and Stephan Mandt},
        journal = {International Conference on Learning Representations},
        year={2025}
      }
    </code></pre>
  </div>
</section>

<!-- Footer -->
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            &copy; Copyright
            <span id="copyright">
              <script>
                  document.getElementById('copyright').appendChild(document.createTextNode(new Date().getFullYear()))
              </script>
            </span>
            Justus Will. Adapted from <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">here</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
